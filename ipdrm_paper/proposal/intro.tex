\section{Introduction}
\label{s:intro}
As extreme computing architectures have continued to evolve, it has become increasingly obvious that as we transition towards exascale-capable computing hardware, I/O will become a significant problem.  It is projected that we will not experience a significant increase in I/O bandwidth as we go through the next 100x increase in compute capabilities.  The traditional HPC approach of simply writing complete checkpoints and analyzing them later for their scientific insights will become more and more costly.  As such, in situ analysis and visualization toolkits with the capability to reduce, process, and otherwise mitigate the raw increase in throughput are increasingly important.  

For instance, we have worked with a number of scientific codes from the combustion, materials science, and \ldots

Several such in situ frameworks already exist~\cite{Catalyst,libSim,Glean,Flexpath}, and much on-going research in the space promises to expand on some of the techniques for management and placement that are needed.  Indeed, some scientific codes have been addressing similar such constraints for years, by in-lining analytics functions and performing complicated MPI communicator subdivisions in order to allow simulation and analytics to co-exist.  One key observation, however, is that there is a lack of portability to the resulting implementations; they require a great deal of tuning and/or runtime placement control in order to make them function as would be desired.  This paper describes our work on \sys, a set of generic, reusable components for in situ processing. These are distributed, in situ data analysis and manipulation tools that can be chained together to form a variety of real-time workflows, so as to provide analytical results during the execution of the primary scientific code.

change this: no inline
Here, it is important to be specific about our use of the words in situ, as they can mean different things to different parts of the community.  We want our components to be generic in terms of supporting all of the concepts of in situ -- in-lined directly into the simulation code, co-located in a separate thread or process on the same node, as well as on separate nodes but within the same machine.  There are obviously memory contention, buffering, and transfer costs that differ between all of these placement choices. The performance of such components is also expected to vary based on the resources they are allocated (eg. number of processors), the platform they are used on, and the workflow that they are part of. The advantage of using generic components, however, is the ability for the scientist assembling the workflow to predict to some extent such variations in performance, and therefore to configure the workflow based on certain guidelines. 

In this work, in addition to presenting a number of existing \sys components and insights in the design of additional components that they may interface with, we explore in depth the performance variations of in situ workflows that use \sys. Based on our results, we provide guidelines for the assembly and runtime configuration of such workflows.

